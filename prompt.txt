FYI

GENERAL FLOW

We read /data/birdclef/train.csv. The file contains columns 'primary_label', 'secondary_labels', 'type', 'filename', 'collection',
       'rating', 'url', 'latitude', 'longitude', 'scientific_name',
       'common_name', 'author', 'license'.
We will be using 'primary_label', 'secondary_labels', 'type', 'filename', 'rating', 'latitude', 'longitude' For our analysis.
Observing the data, I found that for the files that has rating of 5 they only had one label each.

Example train.csv from /data/birdclef/train.csv
primary_label,secondary_labels,type,filename,collection,rating,url,latitude,longitude,scientific_name,common_name,author,license
1139490,[''],[''],1139490/CSA36385.ogg,CSA,0,http://colecciones.humboldt.org.co/rec/sonidos/IAvH-CSA-36385/IAvH-CSA-36385.mp3,7.3206,-73.7128,Ragoniella pulchella,Ragoniella pulchella,Fabio A. Sarria-S,cc-by-nc-sa 4.0
1139490,[''],[''],1139490/CSA36389.ogg,CSA,0,http://colecciones.humboldt.org.co/rec/sonidos/IAvH-CSA-36389/IAvH-CSA-36389.mp3,7.3206,-73.7128,Ragoniella pulchella,Ragoniella pulchella,Fabio A. Sarria-S,cc-by-nc-sa 4.0
1192948,[''],[''],1192948/CSA36358.ogg,CSA,0,http://colecciones.humboldt.org.co/rec/sonidos/IAvH-CSA-36358/IAvH-CSA-36358.mp3,7.3791,-73.7313,Oxyprora surinamensis,Oxyprora surinamensis,Fabio A. Sarria-S,cc-by-nc-sa 4.0


We will first construct our 'golden' dataset with these 5 rating one-labeled data. divide them into 10 second chunks and drop bad chunks, drop duplicate, drop human voices.
Their label tensor will be 206 dimension and only has 1 for 1 corresponding index. class and index mapping is given in CFG. File's directory is given at CFG too.
After processing the data, we now have 10 seconds chunks mel-spectogram tensor and corresponding label tensor. We need to save the meta data in new train_metadata.csv file in current directory.
This train_metadata file will have each row for a chunk with columns 'filename', 'end_sec', 'mel_path', 'label_path', 'weight'.
With this golden data, we will now construct training database further but only with those under-represented.
The goal is to make as promising data as possible for initial training. Since there are about 26000 audio files and exactly 206 species, I want to add training files with following rule.
I have following "rate_count.csv" file ready at my home directory.

primary_label,rating,count
21038,0,2
21116,0,2
21211,0,8
21211,2,4
21211,3,44
21211,4,19
21211,5,1
22333,0,43
22333,3,1
22333,4,2
22333,5,1
22973,0,40
...

With this file we selectively choose files to make them into mel chunks. With some rules, we choose so called 'golden' filebase for initial training.
For instance, if we have certain species with more than 100 5 rating files, we don't collect them any more.
Also, we must include all the files that has sum of less than 20, we include all of them regardless of their ratings.
With this rule in mind, we select files. Since now files have minorities, we should start doing the labeling.
If there's not secondary label, we just create the one hot encoded vector label and save it with mel file and record this into train_metadata.csv.
However, if there's secondary label, we first mark primary label's class with 1 and secondary labels with 0.05s.
For instance, if a file has secondary label of 5 species, from the first to last in the list they get labels for 0.05.
For the weight, if the file is rated 5 and has only one label, it has highest weight which is 1. However, if the file is from minority (less than 20) they also get weight of 1.
weight will be used in dataloader for sampling the chunks.
Now for the rest of the files, we use the similar strategy. We will control the data by pseudo labelling and weights.
Files from minorities will get higher weights and files from abundant species will get smaller weights.
For the labels, in initialization, primary label gets 1 and secondary labels get 0.05. I haven't decided on weight strategy so you should find your best way to do this.
After initial set up with labelled data is done, we will train the model.
We will be training 3 best models for each: efficientnet and regnety. We will save the model results in /data/birdclef/models with proper names.
Though previous code uses benchmarks, we will not be using benchmarks of any. Our 6 models will become benchmarks.

Once the training is done, we will make inferences based on trained models on chunks so we can make them more precise.
For instance, with this process, we will be able to identify exactly which chunks contain birdcalls and which chunks contain secondary labels.
Once inference is done, we will compare the result with actual train_metadata.
If certain chunk does have species with higher probability than 0.5 and in metadata it is said to have such species(first or secondary label), then we will update the label for that species of that chunk into 1.
Now once label is updated and noises are dropped, we will do the training again with updated label.
Such overfitting is (I think) good because our competition is closed set on 206 classes of birds.
We will repeat the process about 5 times and then we will have our best 6 models.

Now it's time to label unlabeled soundscapes.

First we will make inferences and create pseudo labels with our model.
Then, Using our 'golden data' with all the classes available as validation set, we will train our model with mixture of chunks from labeled and pseudo labelled data.
After some iteration, we will have our 6 another updated models.

Then, we will apply mixing of sounds(using golden data to create soundscapes) and synthetic data to create additional datasets.
With these additional dataset, we will also train the model again.

Then, we will submit.


TRAINING DETAILS

More specifically, training and inference will be done with following steps.
1. Batch of mels and labels will be loaded for training. As we load, some additional processing such as augmentation, masking will be done.
2. In the training, We will be using 10 seconds chunk and use CE(Cross Entropy, NOT BINARY cross entropy) with 206 labels.
3. we will use weights of 0.5 of first half and 0.5 of second half for prediction probability. Loss will be calculated based on this procedure.
4. Then, we will save the best 3 models to the /models/ directory with efficientnet_[current time].pth or regnety_[current time].pth.
5. Inference will use these average of time chunks from each models to produce prediction probability. For each model, 3 models min will be used as prediction for labeling. Among 2 results from each model, we will again average the probability to produce final prediction for each chunk.
6. For inference, it is complicated. We will use consecutive 5 chunks (t-2, t-1, t, t+1, t+2) and average the probability. This will yield prob for efficientnet_1.
7. Among efficientnet_1, efficientnet_2, efficientnet_3 we will use min of these 3 probs for one single prob labels for efficiennet. Among prob from efficientnet and regnety, we will average them.
8. This will yield one final probability labels for each 5 second chunk. We will now save updated label for each chunk in our training database.
9. This ends training-inference procedure.

SPECIFIC AUTOML WORKFLOW

Following is how I will run the automl.

1. ssh to my server and move to the project directory.
2. tmux new -s birdclef
3. conda activate birdclef
4. Run automl with initial mode like --initial
 - This will build 'golden' initial DATABASE with 10 seconds chunks in DATABASE/ directory: DATABASE/mels, DATABASE/labels, DATABASE/train_metadata.csv
 - After golden database with all 206 classes created, it will train initial 6 models, 3 efficientnet, 3 regnety.
 - Use these models to do inference and create labels in train_soundscapes data. Read each file in /data/birdclef/train_soundscapes, use our inference logic to label them. Save the mels, labels, and metadata. Create flag for soundscape files in metadata.
 - No additional inference is run here, prints initialization complete.
5. Then, I will run automl and it has 3 stages. This will be iterated n times as argument --iterate n or something like this.
 - 1st stage: Randomly sample 2000 files from train_audio focusing on minority species. Make the copy .ogg files and save the copies in DATABASE/samples directory with names original_name_copied_[time stamp].ogg. Then, Use such copied ogg files to create mels with proper processing such as dropping noise, dropping no sounds removing voices, etc. Then, labels, add lines to train_metadata.csv for mapping.
 - 2nd stage: Train the model. Apply all necessary augmentations or techniques. Now we have new 6 .pth checkpoints updated and saved.
 - 3rd stage: Inference and update labels in soundscapes files. For new label vector of each species, p_new = p_old + \sqrt{p(1-p)}/260 is updating rule for probability but you can use better ones.
6. Lastly, After iterations are complete, save the resulting models, labels. Also save result summary(running time collected, logging, results) in one file as .txt and save it into /output/ directory.
