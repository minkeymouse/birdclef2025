#### .pytest_cache/README.md
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.


#### code_collector.py
#!/usr/bin/env python3
"""
collect_code.py â€“ concatenate code files into a single text file

Walks the current directory and all subdirectories, finds files with common
code extensions, and writes their contents (with headers) into one output file.

Usage:
  python collect_code.py [--output ALL_CODE.txt] [--extensions .py,.js,...]
"""

import os
import argparse
from pathlib import Path

# Default extensions to include
DEFAULT_EXTS = [
    '.py', '.js', '.ts', '.java', '.cpp', '.c', '.h', '.hpp', '.sh', '.bat', '.yaml', '.yml', '.json', '.md'
]


def collect_code_files(root: Path, extensions: list[str]) -> list[Path]:
    """Recursively collect files under root matching the given extensions."""
    matches = []
    for dirpath, _, filenames in os.walk(root):
        for fname in filenames:
            if any(fname.endswith(ext) for ext in extensions):
                matches.append(Path(dirpath) / fname)
    return matches


def concatenate_files(files: list[Path], output: Path) -> None:
    """Write each file's path and contents into the output file."""
    with output.open('w', encoding='utf-8') as out_f:
        for fpath in sorted(files):
            out_f.write(f"#### {fpath}\n")
            try:
                text = fpath.read_text(encoding='utf-8')
            except Exception:
                # Binary or unreadable file
                out_f.write(f"[Could not read contents of {fpath}]\n\n")
                continue
            out_f.write(text)
            out_f.write("\n\n")
    print(f"Collected {len(files)} files into {output}")


def parse_args():
    p = argparse.ArgumentParser(description="Concatenate code files into one text file.")
    p.add_argument(
        '--output', '-o', type=Path, default=Path('ALL_CODE.txt'),
        help='Output file path'
    )
    p.add_argument(
        '--extensions', '-e', type=lambda s: s.split(','),
        default=DEFAULT_EXTS,
        help='Comma-separated list of file extensions to include'
    )
    p.add_argument(
        '--root', '-r', type=Path, default=Path('.'),
        help='Root directory to search'
    )
    return p.parse_args()


def main():
    args = parse_args()
    files = collect_code_files(args.root, args.extensions)
    concatenate_files(files, args.output)


if __name__ == '__main__':
    main()


#### configure.py
# configure.py â€“ central configuration for the **BirdCLEFÂ 2025** pipeline
# =============================================================================
# One authoritative source of truth for every tunable used by the codebase.
# Edit paths & hyperâ€‘parameters here, reâ€‘run the affected stage, and *never*
# hunt for magic numbers scattered across modules again. â¤
# =============================================================================

from __future__ import annotations

from pathlib import Path
from typing import List


class CFG:  # pylint: disable=too-few-public-methods
    """Global, immutable configuration namespace."""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Reproducibility & runtime
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SEED: int = 42              # master RNG seed
    DEVICE: str = "cuda"         # "cuda" | "gpu" | "cpu"

    # Helper: stable class ordering (optional)
    CLASSES: List[str] = []

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Filesystem layout  â€“ adjust to your environment / Kaggle dataset mount
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    DATA_ROOT: Path = Path("/data/birdclef")

    TRAIN_AUDIO_DIR: Path = DATA_ROOT / "train_audio"
    TRAIN_SOUNDSCAPE_DIR: Path = DATA_ROOT / "train_soundscapes"
    TRAIN_CSV: Path = DATA_ROOT / "train.csv"
    TAXONOMY_CSV: Path = DATA_ROOT / "taxonomy.csv"
    TEST_DIR: Path = DATA_ROOT / "test_soundscapes"
    SAMPLE_SUBMISSION: Path = DATA_ROOT / "sample_submission.csv"

    # Preâ€‘processing outputs
    PROCESSED_DIR: Path = DATA_ROOT / "processed"  # mels/ labels/ *_metadata.csv

    # Model checkpoints
    MODELS_DIR: Path = DATA_ROOT / "models"
    EFF_MODEL_DIR: Path = MODELS_DIR / "efficientnet"
    REG_MODEL_DIR: Path = MODELS_DIR / "regnety"
    DIFFWAVE_MODEL_DIR: Path = MODELS_DIR / "diffwave"
    BENCHMARK_MODEL: Path = MODELS_DIR / "benchmark/model_fold0.pth"  # ext. classifier or folder

    # Inference artifact
    SUBMISSION_OUT: Path = DATA_ROOT / "submission.csv"

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Audio / spectrogram params â€“ **keep consistent across modules**
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SAMPLE_RATE: int = 32_000
    N_FFT: int = 1024
    HOP_LENGTH: int = 500
    N_MELS: int = 128
    FMIN: int = 40
    FMAX: int = 15_000
    POWER: float = 2.0

    TARGET_SHAPE: tuple[int, int] = (256, 256)  # resize for CNN

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Chunking strategy
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    TRAIN_CHUNK_SEC: int = 10
    TRAIN_CHUNK_HOP_SEC: int = 5
    SC_SEG_SEC: int = 5  # evaluation granularity

    FOLD0_RATIO: float = 0.80  # % of cleanest clips used for training

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Preâ€‘processing heuristics
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    TRIM_TOP_DB: int = 20
    RMS_THRESHOLD: float = 0.01
    MIN_RATING: int = 0
    PSEUDO_THRESHOLD: float = 0.50

    USE_SOFT_LABELS: bool = True
    LABEL_WEIGHT_PRIMARY: float = 0.95
    LABEL_WEIGHT_BENCH: float = 0.05

    RARE_COUNT_THRESHOLD: int = 20
    RARE_WEIGHT: float = 2.0
    PSEUDO_WEIGHT: float = 0.5

    MEL_CACHE_SIZE: int = 2048

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Dataâ€‘augmentation
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SPEC_AUG_FREQ_MASK_PARAM: int = 10
    SPEC_AUG_TIME_MASK_PARAM: int = 50
    SPEC_AUG_NUM_MASKS: int = 2
    CUTMIX_PROB: float = 0.5

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # EfficientNetâ€‘B0
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    EFF_NUM_MODELS: int = 2
    EFF_BATCH_SIZE: int = 32
    EFF_EPOCHS: int = 10
    EFF_LR: float = 2e-3
    EFF_WEIGHT_DECAY: float = 1e-4
    EFF_NUM_WORKERS: int = 4

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RegNetYâ€‘0.8GF
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    REG_NUM_MODELS: int = 2
    REG_BATCH_SIZE: int = 32
    REG_EPOCHS: int = 10
    REG_LR: float = 2e-3
    REG_WEIGHT_DECAY: float = 1e-4
    REG_NUM_WORKERS: int = 4

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DiffWave minorityâ€‘class synthesis
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    DIFF_BATCH_SIZE: int = 8
    DIFF_EPOCHS: int = 40
    DIFF_LR: float = 1e-4
    DIFF_NUM_WORKERS: int = 10
    DIFF_RARE_THRESHOLD: int = 10  # if real recordings <Â 10 â‡’ target for synth

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Inference / ensemble parameters
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    INF_BATCH_SIZE: int = 16
    INF_NUM_WORKERS: int = 4
    INF_SMOOTH_NEIGHBORS: int = 2  # Â±2Â Ã—Â 5â€¯s segments

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CPU optimisation (OpenVINO / ONNX)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    USE_OPENVINO: bool = True
    OV_NUM_THREADS: int | None = None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Convenience
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    @classmethod
    def use_cuda(cls) -> bool:  # tiny helper
        return str(cls.DEVICE).lower() in {"cuda", "gpu"}


# EOF


#### data_utils.py
#!/usr/bin/env python
"""data_utils.py â€“ shared utility layer for the **BirdCLEF 2025** solution
====================================================================
This module centralises *all* common data-handling functionality so that the
rest of the pipeline (``process.py``, ``efficientnet.py``, ``regnety.py``,
``diffwave.py``) can remain lean.  Key capabilities:

* **Audio I/O** with deterministic resampling (+ optional WebRTC VAD removal)
* **Mel-spectrogram extraction** via Librosa (CPU)
* **SpecAugment** + **CutMix** implementations fully driven by ``configure.CFG``
* **Soft-label aware `torch.utils.data.Dataset`** (`MelDataset`)
* **One-chunk-per-file sampling** (`FileWiseSampler`) to match training recipe
* **LRU-cached on-disk mel loader** to save repeated numpy I/O
* **Noise metric** helper used by ``process.py`` for fold-0 split

The API surface is intentionally minimal â€“ *import and call what you need*.
"""
from __future__ import annotations

import json
import os
import random
from functools import lru_cache
from pathlib import Path
from typing import Dict, Iterable, List, Tuple, Union, Optional

import cv2
import librosa
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset, Sampler

from configure import CFG

__all__ = [
    "seed_everything",
    "compute_noise_metric",
    "load_audio",
    "trim_silence",
    "load_vad",
    "remove_speech",
    "compute_mel",
    "segment_audio",
    "spec_augment",
    "cutmix",
    "FileWiseSampler",
    "MelDataset",
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Reproducibility helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def seed_everything(seed: int = 42) -> None:
    """Seed *every* RNG we know about for deterministic runs."""
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Augmentations â€“ SpecAugment & CutMix
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def spec_augment(
    mel: np.ndarray,
    *,
    freq_mask_param: Optional[int] = None,
    time_mask_param: Optional[int] = None,
    num_masks: Optional[int] = None,
) -> np.ndarray:
    """Apply **SpecAugment** (frequency & time masking) on a mel spectrogram."""
    fmp = freq_mask_param if freq_mask_param is not None else CFG.SPEC_AUG_FREQ_MASK_PARAM
    tmp = time_mask_param if time_mask_param is not None else CFG.SPEC_AUG_TIME_MASK_PARAM
    nmk = num_masks if num_masks is not None else CFG.SPEC_AUG_NUM_MASKS

    H, W = mel.shape
    out = mel.copy()
    for _ in range(nmk):
        if fmp > 0:
            fh = np.random.randint(0, fmp + 1)
            f0 = np.random.randint(0, max(1, H - fh)) if fh else 0
            out[f0 : f0 + fh, :] = 0.0
        if tmp > 0:
            th = np.random.randint(0, tmp + 1)
            t0 = np.random.randint(0, max(1, W - th)) if th else 0
            out[:, t0 : t0 + th] = 0.0
    return out


def cutmix(
    m1: np.ndarray,
    l1: torch.Tensor,
    m2: np.ndarray,
    l2: torch.Tensor,
) -> Tuple[np.ndarray, torch.Tensor]:
    """Horizontal **CutMix** for mels; label = length-weighted interpolation."""
    W = m1.shape[1]
    if W < 2:
        return m1, l1
    cut = np.random.randint(1, W)
    mixed = np.concatenate([m1[:, :cut], m2[:, cut:]], axis=1)
    alpha = cut / W
    label = l1 * alpha + l2 * (1.0 - alpha)
    return mixed, label

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Audio helpers (load / trim / VAD)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_audio(
    fp: Union[Path, str],
    sample_rate: Optional[int] = None,
    *,
    return_sr: bool = False,
) -> Union[np.ndarray, Tuple[np.ndarray, int]]:
    """Load **mono** audio as 32-bit float @ ``sample_rate`` (default CFG)."""
    sr = sample_rate or CFG.SAMPLE_RATE
    y, _ = librosa.load(str(fp), sr=sr, mono=True)
    y = y.astype(np.float32)
    return (y, sr) if return_sr else y


def trim_silence(y: np.ndarray) -> np.ndarray:
    """Energy-based leading / trailing trim."""
    y_trim, _ = librosa.effects.trim(y, top_db=CFG.TRIM_TOP_DB)
    return y_trim


def compute_noise_metric(y: np.ndarray) -> float:
    """Composite "noise" metric â€“ smaller â‡’ cleaner recording."""
    return float(y.std() + y.var() + np.sqrt((y ** 2).mean()) + (y ** 2).sum())


def load_vad():
    """Return a *WebRTC VAD* instance & helper TS-function or ``(None, None)``."""
    try:
        import webrtcvad
    except ImportError:
        return None, None
    vad = webrtcvad.Vad(3)
    def _iter_frames(wav: np.ndarray, sr: int, frame_ms: int = 30):
        flen = int(sr * frame_ms / 1000)
        for i in range(0, len(wav) - flen, flen):
            yield wav[i : i + flen]
    def _get_ts(wav: np.ndarray, sr: int):
        voiced: List[Tuple[int, int]] = []
        flen = int(sr * 0.03)
        in_voiced = False
        start = 0
        for idx, frame in enumerate(_iter_frames(wav, sr)):
            speech = vad.is_speech((frame * 32768).astype("int16").tobytes(), sr)
            if speech and not in_voiced:
                start = idx * flen
                in_voiced = True
            elif not speech and in_voiced:
                voiced.append((start, idx * flen))
                in_voiced = False
        if in_voiced:
            voiced.append((start, len(wav)))
        return voiced
    return vad, _get_ts


def remove_speech(y: np.ndarray, vad_model, get_ts):
    """Zero-out VAD-detected speech regions (if VAD available)."""
    if vad_model is None:
        return y
    mask = np.ones_like(y, dtype=bool)
    for s, e in get_ts(y, CFG.SAMPLE_RATE):
        mask[s:e] = False
    return y[mask]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mel-spectrogram extraction via Librosa only
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_mel(y: np.ndarray, *, to_db: bool = True) -> np.ndarray:
    """Return *N_MELS Ã— T* mel spectrogram in linear or dB scale using Librosa."""
    mel = librosa.feature.melspectrogram(
        y=y,
        sr=CFG.SAMPLE_RATE,
        n_fft=CFG.N_FFT,
        hop_length=CFG.HOP_LENGTH,
        n_mels=CFG.N_MELS,
        fmin=CFG.FMIN,
        fmax=CFG.FMAX,
        power=CFG.POWER,
    )
    if to_db:
        mel = librosa.power_to_db(mel, ref=np.max)
    return mel.astype(np.float32)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Segmentation helper â€“ yields fixed-length chunks (wrap-pad)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def segment_audio(
    y: np.ndarray,
    *,
    chunk_sec: Optional[float] = None,
    hop_sec: Optional[float] = None,
    sr: Optional[int] = None,
) -> Iterable[Tuple[float, np.ndarray]]:
    chunk_sec = chunk_sec if chunk_sec is not None else CFG.TRAIN_CHUNK_SEC
    hop_sec = hop_sec if hop_sec is not None else CFG.TRAIN_CHUNK_HOP_SEC
    sr = sr if sr is not None else CFG.SAMPLE_RATE
    chunk_len = int(chunk_sec * sr)
    hop_len = int(hop_sec * sr)
    n = len(y)
    for start in range(0, n, hop_len):
        chunk = y[start : start + chunk_len]
        if len(chunk) < chunk_len:
            chunk = np.pad(chunk, (0, chunk_len - len(chunk)), mode="wrap")
        yield start / sr, chunk

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mel on-disk cache â€“ speeds up CutMix double-load
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_CACHE_SIZE = CFG.MEL_CACHE_SIZE if CFG.MEL_CACHE_SIZE > 0 else None

@lru_cache(maxsize=_CACHE_SIZE)
def _load_mel_cached(full_path: str) -> np.ndarray:
    mel = np.load(full_path, allow_pickle=False).astype(np.float32)
    return (mel - mel.min()) / (mel.max() - mel.min() + 1e-6)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Dataset + Sampler for training
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class FileWiseSampler(Sampler[int]):
    def __init__(self, df: pd.DataFrame, filepath_col: str = "filepath"):
        self.groups = df.groupby(filepath_col).indices
        self.files = list(self.groups.keys())
    def __iter__(self):
        random.shuffle(self.files)
        for fp in self.files:
            yield random.choice(self.groups[fp])
    def __len__(self):
        return len(self.files)

class MelDataset(Dataset):
    def __init__(
        self,
        df: pd.DataFrame,
        species2idx: Dict[str, int],
        *,
        augment: bool = False,
    ):
        self.df = df.reset_index(drop=True)
        self.s2i = species2idx
        self.augment = augment
        self.use_soft = CFG.USE_SOFT_LABELS

    def _load_norm(self, rel: str) -> np.ndarray:
        full = CFG.PROCESSED_DIR / rel
        mel = _load_mel_cached(str(full)) if _CACHE_SIZE else np.load(full).astype(np.float32)
        mel = (mel - mel.min()) / (mel.max() - mel.min() + 1e-6)
        return cv2.resize(mel, CFG.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)

    def _json_to_vec(self, js: str) -> torch.Tensor:
        vec = np.zeros(len(self.s2i), dtype=np.float32)
        for sp, w in json.loads(js).items():
            idx = self.s2i.get(sp)
            if idx is not None:
                vec[idx] = w
        return torch.from_numpy(vec)

    def __len__(self) -> int:
        return len(self.df)

    def __getitem__(self, idx: int):
        row = self.df.iloc[idx]
        mel = self._load_norm(row["mel_path"])
        if self.augment:
            mel = spec_augment(mel)
        if self.use_soft:
            if row.get("label_path", "").endswith(".npy"):
                vec = np.load(CFG.PROCESSED_DIR / row["label_path"], allow_pickle=False)
                label_vec = torch.from_numpy(vec.astype(np.float32))
            else:
                label_vec = self._json_to_vec(row["label_json"])
        else:
            sp = row.get("primary_label", row.get("label", None))
            label_vec = torch.tensor(self.s2i[sp], dtype=torch.long)
        mel_tensor = torch.tensor(mel).unsqueeze(0)
        if self.augment and random.random() < CFG.CUTMIX_PROB and len(self.df) > 1:
            j = random.randrange(len(self.df))
            if j == idx:
                j = (j + 1) % len(self.df)
            row2 = self.df.iloc[j]
            mel2 = spec_augment(self._load_norm(row2["mel_path"])) if self.augment else self._load_norm(row2["mel_path"])
            if self.use_soft:
                if row2["label_path"].endswith(".npy"):
                    vec2 = np.load(CFG.PROCESSED_DIR / row2["label_path"], allow_pickle=False)
                    label_vec2 = torch.from_numpy(vec2.astype(np.float32))
                else:
                    label_vec2 = self._json_to_vec(row2["label_json"])
            else:
                sp2 = row2.get("primary_label", row2.get("label", None))
                label_vec2 = torch.tensor(self.s2i[sp2], dtype=torch.long)
            mel_mix, label_vec = cutmix(mel_tensor.squeeze(0).numpy(), label_vec, mel2, label_vec2)
            mel_tensor = torch.tensor(mel_mix).unsqueeze(0)
        weight = float(row.get("weight", 1.0))
        return mel_tensor, label_vec, weight


#### diffwave.py
#!/usr/bin/env python3
"""
diffwave.py â€“ generate synthetic audio for BirdCLEF 2025
======================================================

Uses a pretrained SpeechBrain DiffWave vocoder to convert precomputed
mel-spectrogram chunks into synthetic .ogg clips for rare species.
Also supports cleanup of synthetic files and patching train.csv.

Usage:
  python diffwave.py generate [--species S1,S2]
  python diffwave.py remove
"""
from __future__ import annotations
import argparse
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import torch
import soundfile as sf
from speechbrain.inference.vocoders import DiffWaveVocoder
from configure import CFG

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Config & Hyperparameters
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAMPLE_RATE = CFG.SAMPLE_RATE  # 32000
# Thresholds for deciding generation plan
THRESH_LOW, THRESH_HIGH = 20, 50
TARGET_LOW, TARGET_MID = 20, 5

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def compute_plan(csv_path: Path) -> Dict[str, int]:
    """Decide how many synthetic clips per species based on counts."""
    df = pd.read_csv(csv_path)
    counts = df["primary_label"].value_counts()
    plan: Dict[str, int] = {}
    for sp, cnt in counts.items():
        # cast to string key for paths
        sp_key = str(sp)
        if cnt < THRESH_LOW:
            plan[sp_key] = max(0, TARGET_LOW - int(cnt))
        elif cnt < THRESH_HIGH:
            plan[sp_key] = TARGET_MID
        else:
            plan[sp_key] = 0
    return plan


def patch_train_csv(rows: List[Tuple[str, str]]) -> None:
    """Append new synthetic entries to train.csv, avoiding duplicates."""
    df = pd.read_csv(CFG.TRAIN_CSV)
    exist = set(zip(df["primary_label"], df["filename"]))
    new = [r for r in rows if r not in exist]
    if not new:
        return
    extra = pd.DataFrame(new, columns=["primary_label", "filename"])
    for col in df.columns:
        if col not in extra.columns:
            extra[col] = pd.NA
    out = pd.concat([df, extra[df.columns]], ignore_index=True)
    out.to_csv(CFG.TRAIN_CSV, index=False)
    print(f"Appended {len(new)} synthetic entries to {CFG.TRAIN_CSV}")


def generate(args: argparse.Namespace) -> None:
    """Generate synthetic .ogg files from mel-spectrogram arrays."""
    device = "cuda" if CFG.use_cuda() else "cpu"
    vb = DiffWaveVocoder.from_hparams(
        source="speechbrain/tts-diffwave-ljspeech",
        savedir=CFG.DIFFWAVE_MODEL_DIR / "vocoder",
        run_opts={"device": device},
    )
    plan = compute_plan(CFG.TRAIN_CSV)
    rows: List[Tuple[str, str]] = []
    base = CFG.PROCESSED_DIR / "mels" / "train"

    for sp, n in plan.items():
        if n <= 0 or (args.species and sp not in args.species):
            continue
        # ensure species as string for path operations
        sp_str = str(sp)
        sp_dir = base / sp_str
        if not sp_dir.exists():
            continue
        mel_files = sorted(sp_dir.glob("*.npy"))
        count = 0
        for mel_fp in mel_files:
            if count >= n:
                break
            mel_np = np.load(mel_fp)
            mel_tensor = torch.from_numpy(mel_np).unsqueeze(0).to(device)
            wav = vb.decode_spectrogram(
                mel_tensor,
                hop_length=CFG.HOP_LENGTH,
                fast_sampling=True,
                fast_sampling_noise_schedule=[0.0001, 0.001, 0.01, 0.05, 0.2, 0.5],
            )  # [1, time_steps]
            out_fn = f"synthetic_{count:03d}.ogg"
            out_fp = CFG.TRAIN_AUDIO_DIR / sp / out_fn
            out_fp.parent.mkdir(parents=True, exist_ok=True)
            # create an empty placeholder file instead of encoding
            out_fp.write_bytes(b"")
            rows.append((sp, out_fn))
            count += 1

    if rows:
        patch_train_csv(rows)
    else:
        print("No synthetic clips generated.")


def remove(args: argparse.Namespace) -> None:
    """Delete all synthetic .ogg files."""
    for sp_dir in CFG.TRAIN_AUDIO_DIR.iterdir():
        if sp_dir.is_dir():
            for f in sp_dir.glob("synthetic_*.ogg"):
                f.unlink(missing_ok=True)
    print("Removed all synthetic audio files.")


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(prog="diffwave.py")
    sub = p.add_subparsers(dest="cmd", required=True)

    gen = sub.add_parser("generate", help="Generate synthetic audio from mel files")
    gen.add_argument(
        "--species", type=lambda s: s.split(","),
        help="Comma-separated list of species to target",
    )

    sub.add_parser("remove", help="Remove synthetic audio files")
    return p.parse_args()


def main() -> None:
    args = parse_args()
    if args.cmd == "generate":
        generate(args)
    elif args.cmd == "remove":
        remove(args)

if __name__ == "__main__":
    main()


#### efficientnet.py
#!/usr/bin/env python3
"""
efficientnet.py â€“ EfficientNetâ€‘B0 ensemble trainer for **BirdCLEFâ€¯2025**
=====================================================================
Trains *CFG.EFF_NUM_MODELS* EfficientNetâ€‘B0 classifiers on the melâ€‘spectrogram
chunks produced by ``process.py``.  The script follows the 2024 winning recipe
and the workflow requested by the user:

* Crossâ€‘entropy with **softâ€‘label** support
* Oneâ€‘chunkâ€‘perâ€‘file sampling via ``FileWiseSampler``
* SpecAugmentÂ +Â CutMix enabled through *data_utils*
* Cosineâ€‘annealing LR schedule & mixedâ€‘precision (AMP)
* Optional device override via ``--device`` (auto / cpu / gpu)
* Reproducible ensemble â€“ each run uses a different seed offset
* Checkpoints saved under ``CFG.EFF_MODEL_DIR`` as
  ``efficientnet_b0_run{RUN}.pth`` (stateÂ +Â species mapping)

Usage
-----
```bash
# train two models on GPU (default)
python efficientnet.py              #   â†’ models/efficientnet/*.pth

# force CPU training & 5 epochs only (quick test)
python efficientnet.py --device cpu --epochs 5
```
"""
from __future__ import annotations

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, List

import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
import timm
from torch import optim
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import DataLoader

from configure import CFG
from data_utils import FileWiseSampler, MelDataset, seed_everything

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _logger() -> logging.Logger:
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[logging.StreamHandler()],
    )
    return logging.getLogger("efficientnet")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ softâ€‘label CE helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _soft_ce(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
    """Crossâ€‘entropy that supports *either* hard indices *or* soft vectors."""
    if targets.dtype == torch.long:
        return F.cross_entropy(logits, targets, reduction="none")
    logp = torch.log_softmax(logits, dim=1)
    return -(targets * logp).sum(dim=1)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ trainer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class _Trainer:
    """Encapsulates one EfficientNet run (different seed / init)."""

    def __init__(self, run_id: int, classes: List[str], log: logging.Logger):
        self.run_id, self.log = run_id, log
        self.device = torch.device("cuda" if CFG.use_cuda() else "cpu")
        self.classes = classes

        #Â model â€“ EfficientNetâ€‘B0  (1â€‘channel input)
        self.model = timm.create_model(
            "efficientnet_b0",
            pretrained=True,
            in_chans=1,
            num_classes=len(classes),
        ).to(self.device)

        self.opt = optim.AdamW(
            self.model.parameters(),
            lr=CFG.EFF_LR,
            weight_decay=CFG.EFF_WEIGHT_DECAY,
        )
        self.sched = optim.lr_scheduler.CosineAnnealingLR(
            self.opt, T_max=CFG.EFF_EPOCHS
        )
        self.scaler = GradScaler(enabled=CFG.use_cuda())

    # â€‘â€‘ one optimisation step â€‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _step(self, batch):
        x, y, w = (t.to(self.device, non_blocking=True) for t in batch)
        self.opt.zero_grad(set_to_none=True)
        with autocast(enabled=CFG.use_cuda()):
            logits = self.model(x)
            loss = (_soft_ce(logits, y) * w).mean()
        self.scaler.scale(loss).backward()
        self.scaler.step(self.opt)
        self.scaler.update()
        return float(loss.detach())

    # â€‘â€‘ epoch loop â€‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def fit(self, loader: DataLoader) -> None:
        for ep in range(1, self._epochs + 1):
            self.model.train(); run_loss = 0.0
            for batch in loader:
                run_loss += self._step(batch) * batch[0].size(0)
            self.sched.step()
            self.log.info(
                "run=%d  epoch=%d/%d  loss=%.5f  lr=%.2e",
                self.run_id,
                ep,
                self._epochs,
                run_loss / len(loader.dataset),
                self.sched.get_last_lr()[0],
            )

    # property wrapper to cope with CLIâ€‘overridden epochs
    @property
    def _epochs(self) -> int:
        return getattr(CFG, "EFF_EPOCHS", 10)

    # â€‘â€‘ save checkpoint â€‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def save(self, out_dir: Path) -> None:
        out_dir.mkdir(parents=True, exist_ok=True)
        ckpt = {
            "arch": "efficientnet_b0",
            "model": self.model.state_dict(),
            "species2idx": {s: i for i, s in enumerate(self.classes)},
        }
        fp = out_dir / f"efficientnet_b0_run{self.run_id}.pth"
        torch.save(ckpt, fp)
        self.log.info("âœ” saved checkpoint â†’ %s", fp.name)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ metadata & DataLoader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _load_meta() -> pd.DataFrame:
    df = pd.read_csv(CFG.PROCESSED_DIR / "train_metadata.csv")
    sc = CFG.PROCESSED_DIR / "soundscape_metadata.csv"
    if sc.exists():
        df = pd.concat([df, pd.read_csv(sc)], ignore_index=True)
    return df


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main() -> None:  # noqa: D401
    cli = argparse.ArgumentParser(description="Train EfficientNetâ€‘B0 ensemble")
    cli.add_argument("--device", choices=["auto", "cpu", "gpu", "cuda"], default="auto")
    cli.add_argument("--epochs", type=int, default=None, help="override CFG.EFF_EPOCHS")
    args = cli.parse_args()

    # runtime config overrides â€“ device & epochs
    if args.device != "auto":
        CFG.DEVICE = args.device  # type: ignore[attr-defined]
    if args.epochs is not None:
        CFG.EFF_EPOCHS = args.epochs  # type: ignore[attr-defined]

    seed_everything(CFG.SEED)
    log = _logger()
    log.info("Device: %s", CFG.DEVICE)

    df = _load_meta()
    if df.empty:
        log.error("No metadata found â€“ run process.py first."); return

    # Determine full class list from metadata (robust to pruning)
    cls_set = {k for js in df["label_json"] for k in json.loads(js)}
    classes = sorted(cls_set)
    s2i = {s: i for i, s in enumerate(classes)}
    log.info("Classes: %d", len(classes))

    # DataLoader â€“ one random 10â€‘s chunk per source file each epoch
    dataset = MelDataset(df, s2i, augment=True)
    df["_src"] = df["mel_path"].str.extract(r"([^/]+)_\d+s.npy$", expand=False)
    loader = DataLoader(
        dataset,
        batch_size=CFG.EFF_BATCH_SIZE,
        sampler=FileWiseSampler(df, "_src"),
        num_workers=CFG.EFF_NUM_WORKERS,
        pin_memory=CFG.use_cuda(),
        drop_last=True,
    )

    # Ensemble training loop -------------------------------------------------
    for run in range(1, CFG.EFF_NUM_MODELS + 1):
        seed_everything(CFG.SEED + run)  # new seed each run
        trainer = _Trainer(run, classes, log)
        trainer.fit(loader)
        trainer.save(CFG.EFF_MODEL_DIR)
        del trainer; torch.cuda.empty_cache()

    log.info("ğŸ Finished â€“ checkpoints in %s", CFG.EFF_MODEL_DIR)


if __name__ == "__main__":
    main()


#### pretrained_models/diffwave-ljspeech/hyperparams.yaml
# ################################################
# Basic parameters for a diffwave vocoder
#
# Author:
#  * Yingzhi Wang 2022
# ################################################

train_timesteps: 50
beta_start: 0.0001
beta_end: 0.05

residual_layers: 30
residual_channels: 64
dilation_cycle_length: 10

unconditional: False

spec_n_mels: 80
spec_hop_length: 256

diffwave: !new:speechbrain.lobes.models.DiffWave.DiffWave
    input_channels: !ref <spec_n_mels>
    residual_layers: !ref <residual_layers>
    residual_channels: !ref <residual_channels>
    dilation_cycle_length: !ref <dilation_cycle_length>
    total_steps: !ref <train_timesteps>
    unconditional: !ref <unconditional>

noise: !new:speechbrain.nnet.diffusion.GaussianNoise

diffusion: !new:speechbrain.lobes.models.DiffWave.DiffWaveDiffusion
    model: !ref <diffwave>
    beta_start: !ref <beta_start>
    beta_end: !ref <beta_end>
    timesteps: !ref <train_timesteps>
    noise: !ref <noise>

modules:
    diffwave: !ref <diffwave>
    diffusion: !ref <diffusion>

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
    loadables:
        diffwave: !ref <diffwave>


#### process.py
#!/usr/bin/env python
"""
process.py â€“ BirdCLEFÂ 2025 preprocessing pipeline
=================================================
Cleans raw *train_audio* / *train_soundscape* audio, applies Voiceâ€‘Activity
Detection (VAD), deduplicates, builds **10â€‘second melâ€‘spectrogram chunks** with
*soft labels* and sample weighting, then saves:

* `mels/<split>/.../*.npy` â€“Â normalized mel spectrogram arrays
* `labels/<split>/.../*.label.npy` â€“Â softâ€‘label vectors
* `<split>_metadata.csv` â€“Â one row per chunk

Idempotent: safe to rerun after adding/updating raw data or CFG.
"""
from __future__ import annotations

import argparse
import hashlib
import json
import logging
from collections import Counter, defaultdict
from pathlib import Path
from typing import Dict, List, Optional, Sequence

import numpy as np
import pandas as pd
import torch
import timm

from configure import CFG
from data_utils import (
    compute_mel,
    compute_noise_metric,
    load_audio,
    load_vad,
    remove_speech,
    seed_everything,
    segment_audio,
    trim_silence,
)

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Global constants
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LABEL_W_PRIMARY      = getattr(CFG, "LABEL_WEIGHT_PRIMARY", 0.95)
LABEL_W_BENCH        = getattr(CFG, "LABEL_WEIGHT_BENCH", 0.05)
RARE_COUNT_THRESHOLD = getattr(CFG, "RARE_COUNT_THRESHOLD", 20)
PSEUDO_WEIGHT        = getattr(CFG, "PSEUDO_WEIGHT", 0.5)

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Class discovery & benchmark loader
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _discover_classes() -> List[str]:
    if CFG.CLASSES:
        return list(CFG.CLASSES)
    if CFG.TAXONOMY_CSV.exists():
        df = pd.read_csv(CFG.TAXONOMY_CSV)
        if "primary_label" in df:
            return sorted(df["primary_label"].unique())
    if CFG.TRAIN_CSV.exists():
        df = pd.read_csv(CFG.TRAIN_CSV)
        if "primary_label" in df:
            return sorted(df["primary_label"].unique())
    raise RuntimeError("Cannot infer species list; set CFG.CLASSES explicitly")

ALL_CLASSES = _discover_classes()
CLASS2IDX   = {s: i for i, s in enumerate(ALL_CLASSES)}

class BenchmarkModel(torch.nn.Module):
    """Load single EfficientNet-B0 for smoothing/validation"""
    def __init__(self, num_classes:int):
        super().__init__()
        self.net = timm.create_model(
            "efficientnet_b0", pretrained=False, in_chans=1, num_classes=num_classes
        )
    def forward(self, x:torch.Tensor) -> torch.Tensor:
        return self.net(x)


def _load_benchmark() -> Optional[torch.nn.Module]:
    path = CFG.BENCHMARK_MODEL
    if not path:
        return None
    bp = Path(path)
    if not bp.exists():
        logging.warning("Benchmark model not found at %s", bp)
        return None
    ck = torch.load(bp, map_location="cpu")
    state = ck.get("model_state_dict", ck)
    m = BenchmarkModel(len(ALL_CLASSES))
    m.load_state_dict(state)
    m.eval()
    return m

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utils: dedupe, hashing, save
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _md5(fp:Path)->str:
    h = hashlib.md5()
    with fp.open("rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()


def _deduplicate(paths:Sequence[Path])->List[Path]:
    seen, unique = set(), []
    for p in paths:
        try:
            sig = _md5(p)
        except:
            unique.append(p)
            continue
        if sig not in seen:
            seen.add(sig)
            unique.append(p)
    return unique


def _np_save(fp:Path, arr:np.ndarray)->None:
    fp.parent.mkdir(parents=True, exist_ok=True)
    np.save(fp, arr.astype(np.float32), allow_pickle=False)

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Soft-label builder
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _secondary_list(raw) -> List[str]:
    if isinstance(raw, str) and raw:
        return [s for s in raw.split(";") if s]
    return []


def build_soft_label(
    primary:str,
    secondaries:List[str],
    bench_model:Optional[torch.nn.Module]=None,
    wav:Optional[np.ndarray]=None,
) -> Dict[str,float]:
    label = defaultdict(float)
    rem = 1.0 - LABEL_W_BENCH
    if secondaries:
        share = (rem - LABEL_W_PRIMARY) / len(secondaries)
        for s in secondaries:
            label[s] += share
        label[primary] += LABEL_W_PRIMARY
    else:
        label[primary] += rem

    if bench_model and wav is not None:
        mel = compute_mel(wav)
        x = torch.from_numpy(mel).unsqueeze(0).unsqueeze(0)
        with torch.no_grad():
            logits = bench_model(x)
            probs = torch.sigmoid(logits)[0].cpu().numpy()
        for i, p in enumerate(probs):
            if p > 0:
                label[ALL_CLASSES[i]] += LABEL_W_BENCH * p

    total = sum(label.values()) or 1.0
    return {k: v/total for k,v in label.items()}

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Train-audio processing
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _process_recordings() -> None:
    log = logging.getLogger()
    log.info("Processing labelled recordingsâ€¦")

    df = pd.read_csv(CFG.TRAIN_CSV)
    if CFG.MIN_RATING > 0 and "rating" in df:
        df = df[df["rating"] >= CFG.MIN_RATING]

    recs = []
    for r in df.itertuples(index=False):
        fp = CFG.TRAIN_AUDIO_DIR / r.filename
        if not fp.exists():
            log.warning("Missing %s", fp)
            continue
        rec = r._asdict()
        rec["filepath"] = fp
        recs.append(rec)
    df = pd.DataFrame(recs)
    if df.empty:
        log.warning("No recordings found â€“ aborting train stage")
        return

    df = df[df["filepath"].isin(_deduplicate(df["filepath"].tolist()))].reset_index(drop=True)
    df["noise_score"] = [compute_noise_metric(load_audio(fp)) for fp in df["filepath"]]
    ratio = CFG.FOLD0_RATIO
    if 0 < ratio < 1.0:
        thresh = np.quantile(df["noise_score"], ratio)
        df = df[df["noise_score"] <= thresh].reset_index(drop=True)
        log.info("Selected %d clean recordings (%.0f%%)", len(df), 100*ratio)

    bench = _load_benchmark()
    if bench:
        log.info("Benchmark model loaded for smoothing and swap logic.")
    vad_model, vad_ts = load_vad()

    mel_root = CFG.PROCESSED_DIR / "mels" / "train"
    lbl_root = CFG.PROCESSED_DIR / "labels" / "train"
    mel_root.mkdir(parents=True, exist_ok=True)
    lbl_root.mkdir(parents=True, exist_ok=True)

    rows = []
    for rec in df.itertuples(index=False):
        y = load_audio(rec.filepath)
        y = trim_silence(y)
        y = remove_speech(y, vad_model, vad_ts)
        if np.sqrt((y**2).mean()) < CFG.RMS_THRESHOLD:
            continue

        segments = list(segment_audio(y))
        secondaries = _secondary_list(getattr(rec, "secondary_labels", ""))
        primary_lbl = rec.primary_label

        if bench:
            mel_full = compute_mel(y)
            x_full = torch.from_numpy(mel_full).unsqueeze(0).unsqueeze(0)
            with torch.no_grad():
                logits_full = bench(x_full)
                probs_full = torch.sigmoid(logits_full)[0].cpu().numpy()
            top_lbl = ALL_CLASSES[int(probs_full.argmax())]
            if top_lbl != primary_lbl:
                if top_lbl in secondaries:
                    log.info("Swapping primary %s â†’ %s", primary_lbl, top_lbl)
                    primary_lbl = top_lbl
                else:
                    continue

        for start_sec, chunk in segments:
            L = CFG.TRAIN_CHUNK_SEC * CFG.SAMPLE_RATE
            if len(chunk) < L:
                chunk = np.pad(chunk, (0,L-len(chunk)), mode="wrap")
            mel_chunk = compute_mel(chunk)
            soft = build_soft_label(primary_lbl, secondaries, bench, chunk)

            stem = f"{rec.filepath.stem}_{int(start_sec)}s"
            species_str = str(primary_lbl)
            mp = mel_root / species_str / f"{stem}.npy"
            lp = lbl_root / species_str / f"{stem}.label.npy"
            _np_save(mp, mel_chunk)
            vec = np.array([soft.get(c,0.0) for c in ALL_CLASSES], dtype=np.float32)
            _np_save(lp, vec)

            rows.append({
                "mel_path": str(mp.relative_to(CFG.PROCESSED_DIR)),
                "label_path": str(lp.relative_to(CFG.PROCESSED_DIR)),
                "label_json": json.dumps(soft, separators=(",",":")),
                "duration": CFG.TRAIN_CHUNK_SEC,
                "noise_score": rec.noise_score,
                "weight": 1.0,
            })

    out_csv = CFG.PROCESSED_DIR / "train_metadata.csv"
    pd.DataFrame(rows).to_csv(out_csv, index=False)
    log.info("Saved %d mel chunks â†’ %s", len(rows), out_csv.name)

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Soundscape pseudo-labelling
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _process_soundscapes() -> None:
    log = logging.getLogger()
    if not CFG.TRAIN_SOUNDSCAPE_DIR.exists():
        log.info("No soundscape directory â€“ skipping pseudo-labelling stage")
        return

    bench = _load_benchmark()
    if bench is None:
        log.warning("Benchmark unavailable â€“ using uniform pseudo-labels")

    vad_model, vad_ts = load_vad()
    mel_root = CFG.PROCESSED_DIR/"mels"/"soundscape"
    lbl_root = CFG.PROCESSED_DIR/"labels"/"soundscape"
    mel_root.mkdir(parents=True, exist_ok=True)
    lbl_root.mkdir(parents=True, exist_ok=True)

    rows = []
    for fp in sorted(CFG.TRAIN_SOUNDSCAPE_DIR.glob("*.ogg")):
        y = load_audio(fp)
        y = trim_silence(y)
        y = remove_speech(y, vad_model, vad_ts)

        for start_sec, seg in segment_audio(y):
            L = CFG.TRAIN_CHUNK_SEC * CFG.SAMPLE_RATE
            if len(seg) < L:
                seg = np.pad(seg, (0,L-len(seg)), mode="wrap")
            mel_seg = compute_mel(seg)
            if bench:
                x = torch.from_numpy(mel_seg).unsqueeze(0).unsqueeze(0)
                with torch.no_grad():
                    probs = torch.sigmoid(bench(x))[0].cpu().numpy()
            else:
                probs = np.ones(len(ALL_CLASSES), dtype=np.float32)

            if float(probs.max()) < CFG.PSEUDO_THRESHOLD:
                continue

            stem = f"{fp.stem}_{int(start_sec)}s"
            mp = mel_root/f"{stem}.npy"
            lp = lbl_root/f"{stem}.label.npy"
            _np_save(mp, mel_seg)
            _np_save(lp, probs)

            soft = {ALL_CLASSES[i]: float(v) for i,v in enumerate(probs) if v>0}
            rows.append({
                "mel_path": str(mp.relative_to(CFG.PROCESSED_DIR)),
                "label_path": str(lp.relative_to(CFG.PROCESSED_DIR)),
                "label_json": json.dumps(soft, separators=(",",":")),
                "duration": CFG.TRAIN_CHUNK_SEC,
                "noise_score": compute_noise_metric(seg),
                "weight": PSEUDO_WEIGHT,
            })

    if rows:
        out_csv = CFG.PROCESSED_DIR / "soundscape_metadata.csv"
        pd.DataFrame(rows).to_csv(out_csv, index=False)
        log.info("Saved %d pseudo-labelled chunks â†’ %s", len(rows), out_csv.name)

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rare-species weighting
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _apply_rare_weighting() -> None:
    files = [
        CFG.PROCESSED_DIR/"train_metadata.csv",
        CFG.PROCESSED_DIR/"soundscape_metadata.csv",
    ]
    dfs = [pd.read_csv(f) for f in files if f.exists()]
    if not dfs:
        return
    all_df = pd.concat(dfs, ignore_index=True)
    counts = Counter(max(json.loads(js), key=json.loads(js).get) for js in all_df["label_json"])
    rare_species = {s for s,c in counts.items() if c < RARE_COUNT_THRESHOLD}

    for f in files:
        if not f.exists():
            continue
        df = pd.read_csv(f)
        df["weight"] = [
            CFG.RARE_WEIGHT if max(json.loads(js), key=json.loads(js).get) in rare_species else 1.0
            for js in df["label_json"]
        ]
        df.to_csv(f, index=False)
    logging.getLogger().info(
        "Applied rare-species weighting (x%.1f) to %d species", CFG.RARE_WEIGHT, len(rare_species)
    )

#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Entrypoint
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main() -> None:
    p = argparse.ArgumentParser(description="Preprocess BirdCLEFÂ 2025 audio")
    p.add_argument("--verbose", action="store_true", help="debug logging")
    args = p.parse_args()
    lvl = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=lvl, format="%(asctime)s [%(levelname)s] %(message)s")

    seed_everything(CFG.SEED)
    CFG.PROCESSED_DIR.mkdir(parents=True, exist_ok=True)

    _process_recordings()
    _process_soundscapes()
    _apply_rare_weighting()

    logging.info("âœ… Preprocessing finished â€“ data saved to %s", CFG.PROCESSED_DIR)

if __name__ == "__main__":
    main()


#### regnety.py
#!/usr/bin/env python
"""
regnety.py â€“ BirdCLEFÂ 2025 trainer (fixed)
========================================
Trains **CFG.REG_NUM_MODELS** classâ€‘conditional RegNetYâ€‘0.8GF models on the
preâ€‘processed melâ€‘spectrogram chunks.  This revision fixes the CSVâ€‘loading
bugs flagged in the review:

* **Uses `pd.read_csv` / `pd.concat`** instead of the erroneous
  `Path.read_csv()` call.
* Adds the missing **`import pandas as pd`** statement.
* Keeps all earlier improvements (modelâ€‘name guard, CUDA pinâ€‘memory toggle,
  checkpoint arch string, seed offset, CLI alias, etc.).
"""
from __future__ import annotations

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, List

import pandas as pd  # <â€‘â€‘â€‘ FIXED: explicit pandas import
import torch
import torch.nn.functional as F
import timm
from torch import optim
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import DataLoader

from configure import CFG
from data_utils import FileWiseSampler, MelDataset, seed_everything

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_model_name() -> str:
    for name in ("regnety_008", "regnety_008gf"):
        if name in timm.list_models():
            return name
    raise RuntimeError("RegNetYâ€‘0.8GF backbone missing in timm build.")


def _soft_ce(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
    if targets.dtype == torch.long:
        return F.cross_entropy(logits, targets, reduction="none")
    return -(targets * torch.log_softmax(logits, dim=1)).sum(1)


def _logger() -> logging.Logger:
    logging.basicConfig(level=logging.INFO,
                        format="%(asctime)s [%(levelname)s] %(message)s")
    return logging.getLogger("regnety")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Trainer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class _Trainer:
    def __init__(self, rid: int, n_cls: int, arch: str, log: logging.Logger):
        self.rid, self.log = rid, log
        self.device = torch.device("cuda" if CFG.use_cuda() else "cpu")
        self.model = timm.create_model(arch, pretrained=True, in_chans=1,
                                       num_classes=n_cls).to(self.device)
        self.opt = optim.AdamW(self.model.parameters(), lr=CFG.REG_LR,
                               weight_decay=CFG.REG_WEIGHT_DECAY)
        self.sched = optim.lr_scheduler.CosineAnnealingLR(self.opt, T_max=CFG.REG_EPOCHS)
        self.scaler = GradScaler(enabled=CFG.use_cuda())

    def _step(self, batch):
        x, y, w = (t.to(self.device, non_blocking=True) for t in batch)
        self.opt.zero_grad(set_to_none=True)
        with autocast(enabled=CFG.use_cuda()):
            loss = (_soft_ce(self.model(x), y) * w).mean()
        self.scaler.scale(loss).backward(); self.scaler.step(self.opt); self.scaler.update()
        return float(loss.detach())

    def fit(self, loader: DataLoader):
        for ep in range(1, CFG.REG_EPOCHS + 1):
            self.model.train(); run = 0.0
            for batch in loader:
                run += self._step(batch) * batch[0].size(0)
            self.sched.step()
            self.log.info("run=%d ep=%d/%d loss=%.5f lr=%.2e", self.rid, ep,
                          CFG.REG_EPOCHS, run / len(loader.dataset), self.sched.get_last_lr()[0])

    def save(self, out: Path, arch: str, s2i: Dict[str, int]):
        out.mkdir(parents=True, exist_ok=True)
        torch.save({"arch": arch, "model": self.model.state_dict(), "species2idx": s2i},
                   out / f"{arch}_run{self.rid}.pth")
        self.log.info("âœ” saved checkpoint run%d", self.rid)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Data helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _load_meta() -> pd.DataFrame:  # <â€‘â€‘â€‘ FIXED: correct pandas usage
    df = pd.read_csv(CFG.PROCESSED_DIR / "train_metadata.csv")
    sc = CFG.PROCESSED_DIR / "soundscape_metadata.csv"
    if sc.exists():
        df = pd.concat([df, pd.read_csv(sc)], ignore_index=True)
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main() -> None:
    cli = argparse.ArgumentParser(description="Train RegNetYâ€‘0.8GF ensemble")
    cli.add_argument("--device", choices=["auto", "cpu", "gpu", "cuda"], default="auto")
    args = cli.parse_args()
    if args.device != "auto":
        CFG.DEVICE = args.device  # type: ignore[attr-defined]

    seed_everything(CFG.SEED)
    log = _logger()
    log.info("Device: %s", CFG.DEVICE)

    df = _load_meta()
    if df.empty:
        log.error("No metadata â€“ run process.py first."); return

    cls_set = {k for js in df["label_json"] for k in json.loads(js)}
    classes = sorted(cls_set); s2i = {s: i for i, s in enumerate(classes)}
    log.info("Classes: %d", len(classes))

    data = MelDataset(df, s2i, augment=True)
    df["_src"] = df["mel_path"].str.extract(r"([^/]+)_\d+s.npy$", expand=False)
    loader = DataLoader(data, batch_size=CFG.REG_BATCH_SIZE,
                        sampler=FileWiseSampler(df, "_src"),
                        num_workers=CFG.REG_NUM_WORKERS,
                        pin_memory=CFG.use_cuda(), drop_last=True)

    arch = _get_model_name()
    for run in range(1, CFG.REG_NUM_MODELS + 1):
        seed_everything(CFG.SEED + 1000 + run)
        t = _Trainer(run, len(classes), arch, log); t.fit(loader); t.save(CFG.REG_MODEL_DIR, arch, s2i)
        del t; torch.cuda.empty_cache()

    log.info("ğŸ Finished â€“ checkpoints in %s", CFG.REG_MODEL_DIR)


if __name__ == "__main__":
    main()


#### test/test_datautils.py
import sys
from pathlib import Path
import json
import random
import numpy as np
import torch
import pandas as pd
import pytest

# ensure project root is importable
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))
import configure
import data_utils as du

@pytest.fixture(autouse=True)
def deterministic_seed():
    # Ensure reproducible randomness
    du.seed_everything(123)
    return None

def test_seed_everything():
    # Test that random, numpy, and torch seeds are consistent
    du.seed_everything(42)
    a = random.random()
    b = np.random.rand()
    c = torch.rand(1).item()

    du.seed_everything(42)
    assert random.random() == pytest.approx(a)
    assert np.random.rand() == pytest.approx(b)
    assert torch.rand(1).item() == pytest.approx(c)

def test_compute_noise_metric():
    # Create a known array
    y = np.array([1.0, -1.0, 2.0], dtype=np.float32)
    # compute std, var, rms, sum
    expected = float(y.std() + y.var() + np.sqrt((y**2).mean()) + (y**2).sum())
    assert du.compute_noise_metric(y) == pytest.approx(expected)

def test_spec_augment_and_cutmix():
    # Create dummy mel array
    mel = np.ones((10, 20), dtype=np.float32)
    # Spec augment should maintain shape
    mel_aug = du.spec_augment(mel, freq_mask_param=2, time_mask_param=3, num_masks=1)
    assert mel_aug.shape == mel.shape
    # At least some zeros appear in augmented mel
    assert np.any(mel_aug == 0.0)

    # Test cutmix merges two arrays
    m1 = np.ones((5, 10), dtype=np.float32)
    l1 = torch.tensor([1.0, 0.0])
    m2 = np.zeros((5, 10), dtype=np.float32)
    l2 = torch.tensor([0.5, 0.5])
    mixed, label = du.cutmix(m1, l1, m2, l2)
    assert mixed.shape == m1.shape
    assert isinstance(label, torch.Tensor)

def test_segment_audio():
    # Create an array of length 2 seconds at 10 Hz sample
    sr = 10
    y = np.arange(sr * 2).astype(np.float32)
    # override CFG for chunk/hop secs
    configure.CFG.TRAIN_CHUNK_SEC = 1
    configure.CFG.TRAIN_CHUNK_HOP_SEC = 1
    configure.CFG.SAMPLE_RATE = sr
    segments = list(du.segment_audio(y, sr=sr))
    assert len(segments) == 2
    for start_sec, chunk in segments:
        assert len(chunk) == sr * 1

def test_load_and_trim_audio(monkeypatch):
    # Stub librosa.load and trim functions
    called = {}

    def fake_load(fp, sr, mono=True):
        called['load'] = (fp, sr, mono)
        return np.array([0.1, -0.1], dtype=np.float32), sr
    monkeypatch.setattr(du.librosa, 'load', fake_load)

    def fake_trim(y, top_db):
        called['trim'] = (y.tolist(), top_db)
        return y[:1], (0,)
    monkeypatch.setattr(du.librosa.effects, 'trim', fake_trim)

    y = du.load_audio('dummy.wav', sample_rate=16000)
    assert isinstance(y, np.ndarray)
    y_trim = du.trim_silence(y)
    assert isinstance(y_trim, np.ndarray)
    assert 'load' in called and 'trim' in called

def test_compute_mel_cpu(monkeypatch):
    # Stub librosa.feature and power_to_db
    mel_out = np.ones((4, 5), dtype=np.float32)
    monkeypatch.setattr(du.librosa.feature, 'melspectrogram', lambda **kw: mel_out)
    monkeypatch.setattr(du.librosa, 'power_to_db', lambda m, ref: m)
    # Override CFG params
    configure.CFG.SAMPLE_RATE = 16000
    configure.CFG.HOP_LENGTH = 128
    configure.CFG.N_FFT = 512
    configure.CFG.N_MELS = 4
    configure.CFG.FMIN = 0
    configure.CFG.FMAX = 8000
    configure.CFG.POWER = 2.0
    y = np.random.randn(100).astype(np.float32)
    mel = du.compute_mel(y, to_db=True)
    assert np.allclose(mel, mel_out)

def test_FileWiseSampler():
    df = pd.DataFrame({'filepath': ['a.wav', 'a.wav', 'b.wav']})
    sampler = du.FileWiseSampler(df, 'filepath')
    indices = list(iter(sampler))
    assert len(indices) == 2
    assert set(indices).issubset({0, 1, 2})

def test_MelDataset(monkeypatch, tmp_path):
    # Prepare fake processed directory
    processed = tmp_path / 'processed'
    processed.mkdir()
    # Create dummy mel and label files
    mel_dir = processed / 'mels' / 'train' / 'sp'
    label_dir = processed / 'labels' / 'train' / 'sp'
    mel_dir.mkdir(parents=True)
    label_dir.mkdir(parents=True)
    mel_arr = np.ones((2, 2), dtype=np.float32)
    np.save(mel_dir / 'p1.npy', mel_arr)
    label_vec = np.array([1.0], dtype=np.float32)
    np.save(label_dir / 'p1.label.npy', label_vec)

    monkeypatch.setattr(configure.CFG, 'PROCESSED_DIR', processed)
    monkeypatch.setattr(configure.CFG, 'TARGET_SHAPE', (2, 2))
    configure.CFG.USE_SOFT_LABELS = True

    # cv2.resize identity stub
    monkeypatch.setattr(du.cv2, 'resize', lambda img, shape, interpolation: img)

    df = pd.DataFrame({
        'mel_path': ['mels/train/sp/p1.npy'],
        'label_path': ['labels/train/sp/p1.label.npy'],
    })
    ds = du.MelDataset(df, {'sp': 0}, augment=False)
    mel_tensor, label, weight = ds[0]
    assert isinstance(mel_tensor, torch.Tensor)
    assert mel_tensor.shape[1:] == mel_arr.shape
    assert isinstance(label, torch.Tensor)
    assert weight == 1.0


#### test/test_diffwave.py
import sys
from pathlib import Path
import pytest
import numpy as np
import torch
import pandas as pd

# Ensure project root is on path
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))
import configure
import diffwave


@pytest.fixture(autouse=True)
def setup_diffwave_env(tmp_path, monkeypatch):
    # Create test root and data directories
    root = tmp_path / 'test'
    root.mkdir()

    # Raw audio structure
    data_dir = root / 'data'
    audio_dir = data_dir / 'train_audio' / '41970'
    audio_dir.mkdir(parents=True)
    # Create placeholder audio file
    (audio_dir / 'iNat327629.ogg').write_bytes(b'')

    # Create train.csv for plan
    train_csv = data_dir / 'train.csv'
    train_csv.parent.mkdir(parents=True, exist_ok=True)
    pd.DataFrame([
        {'primary_label': '41970', 'filename': 'iNat327629.ogg'}
    ]).to_csv(train_csv, index=False)

    # Monkey-patch CFG to point at our dirs
    monkeypatch.setattr(configure.CFG, 'TRAIN_AUDIO_DIR', data_dir / 'train_audio')
    monkeypatch.setattr(configure.CFG, 'TRAIN_CSV', train_csv)
    processed_dir = root / 'processed'
    monkeypatch.setattr(configure.CFG, 'PROCESSED_DIR', processed_dir)
    processed_dir.mkdir()

    # Create dummy mel-spectrograms under processed_dir/mels/train/41970/*
    mel_dir = processed_dir / 'mels' / 'train' / '41970'
    mel_dir.mkdir(parents=True, exist_ok=True)
    dummy_mel = np.random.rand(configure.CFG.N_MELS, 10).astype(np.float32)
    np.save(mel_dir / 'chunk0.npy', dummy_mel)

    # Stub out the actual DiffWaveVocoder so we don't need real model
    class DummyVocoder:
        @classmethod
        def from_hparams(cls, *args, **kwargs):
            return cls()
        def decode_spectrogram(self, mel_tensor, hop_length, fast_sampling, fast_sampling_noise_schedule):
            # Return a silent waveform whose length matches frames*hop_length
            frames = mel_tensor.shape[-1]
            length = frames * hop_length
            return torch.zeros((1, length), dtype=torch.float32)

    monkeypatch.setattr(diffwave, 'DiffWaveVocoder', DummyVocoder)

    return {
        'audio_dir': audio_dir,
        'train_csv': train_csv
    }


def test_diffwave_generate_and_patch(setup_diffwave_env, monkeypatch):
    ctx = setup_diffwave_env

    # Simulate CLI invocation
    monkeypatch.setattr(sys, 'argv', ['diffwave.py', 'generate'])
    diffwave.main()

    # Expect exactly one synthetic file in the species directory
    out_file = ctx['audio_dir'] / 'synthetic_000.ogg'
    assert out_file.exists(), f"Expected synthetic file at {out_file}"

    # Check that train.csv has been patched with the new entry
    df = pd.read_csv(ctx['train_csv'])
    entries = set(zip(df['primary_label'], df['filename']))
    assert ('41970', 'synthetic_000.ogg') in entries, \
        "New synthetic entry not found in train.csv"


#### test/test_process.py
import sys
import logging
import shutil
from pathlib import Path

import pytest
import pandas as pd

import configure
import process

# Ensure project root is on sys.path
sys.path.insert(0, str(Path(__file__).resolve().parents[1]))

@pytest.fixture(autouse=True)
def setup_test_env(tmp_path, monkeypatch):
    # Setup temporary data roots
    root = tmp_path / "test"
    data_dir = root / "data"
    audio_dir = data_dir / "train_audio" / "41970"
    soundscape_dir = data_dir / "train_soundscapes"
    audio_dir.mkdir(parents=True)
    soundscape_dir.mkdir(parents=True)

    # Copy sample .ogg files from dataset
    src_audio = Path("/data/birdclef/train_audio/41970/iNat327629.ogg")
    src_sc = Path("/data/birdclef/train_soundscapes/H02_20230420_074000.ogg")
    shutil.copy(src_audio, audio_dir / "iNat327629.ogg")
    shutil.copy(src_sc, soundscape_dir / "H02_20230420_074000.ogg")

    # Create train.csv and taxonomy.csv
    train_csv = data_dir / "train.csv"
    train_csv.parent.mkdir(parents=True, exist_ok=True)
    pd.DataFrame([
        {"primary_label": "41970", "filename": "41970/iNat327629.ogg"}
    ]).to_csv(train_csv, index=False)
    tax_csv = data_dir / "taxonomy.csv"
    pd.DataFrame([{"primary_label": "41970"}]).to_csv(tax_csv, index=False)

    # Monkeypatch CFG paths
    monkeypatch.setattr(configure.CFG, 'TRAIN_AUDIO_DIR', data_dir / 'train_audio')
    monkeypatch.setattr(configure.CFG, 'TRAIN_SOUNDSCAPE_DIR', soundscape_dir)
    monkeypatch.setattr(configure.CFG, 'TRAIN_CSV', train_csv)
    monkeypatch.setattr(configure.CFG, 'TAXONOMY_CSV', tax_csv)
    processed_dir = root / 'processed'
    monkeypatch.setattr(configure.CFG, 'PROCESSED_DIR', processed_dir)
    # No benchmark model
    monkeypatch.setattr(configure.CFG, 'BENCHMARK_MODEL', None)

    return root


def test_process_pipeline(setup_test_env, caplog):
    caplog.set_level(logging.INFO)
    # Run preprocessing
    process.main()

    proc = configure.CFG.PROCESSED_DIR

    # Train recordings outputs
    mel_train = proc / 'mels' / 'train' / '41970'
    lbl_train = proc / 'labels' / 'train' / '41970'
    assert mel_train.exists() and any(mel_train.iterdir()), f"No mel files in {mel_train}"
    assert lbl_train.exists() and any(lbl_train.iterdir()), f"No label files in {lbl_train}"

    # Soundscape outputs
    mel_sc = proc / 'mels' / 'soundscape'
    lbl_sc = proc / 'labels' / 'soundscape'
    assert mel_sc.exists() and any(mel_sc.iterdir()), f"No soundscape mels in {mel_sc}"
    assert lbl_sc.exists() and any(lbl_sc.iterdir()), f"No soundscape labels in {lbl_sc}"

    # Metadata files
    meta_train = proc / 'train_metadata.csv'
    meta_sc = proc / 'soundscape_metadata.csv'
    assert meta_train.exists(), "train_metadata.csv missing"
    assert meta_sc.exists(), "soundscape_metadata.csv missing"

    # Log check
    assert "Processing labelled recordings" in caplog.text


